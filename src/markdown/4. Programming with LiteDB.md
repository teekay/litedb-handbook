# Programming with LiteDB

## Getting started

Alright, time to open the editor and start coding!

### Getting started with LiteDB

LiteDB is written for .NET. It could not be easier to start using it.

Simply create a new C# class library, target `netstandard2.0`, and add the LiteDB dependency using Nuget: `Install-Package LiteDB`.

That‚Äôs it.

### Getting started with SQLite

Compare this with the decisions you have to make when using SQLite.

If you haven‚Äôt done this before, I guarantee you a headache! Just type `sqlite` at [nuget.org](http://nuget.org) and see [how many packages are there](https://www.nuget.org/packages?q=sqlite)!

For the purposes of this tutorial, we will use the [SQLite-net library](https://github.com/praeclarum/sqlite-net). It‚Äôs an excellent multi-platform choice with its own mini-ORM, while you can still use raw SQL if you want to (I do).

### About the example application

This will be more than an academic exercise. You don‚Äôt really know whether a particular library or API works until you hire it to do a real job for you.

The project we‚Äôll use to explore LiteDB capabilities will be a music library. It is one of the key components of [Bewitched](https://tomaskohl.com/apps/bewitched/), my app for DJs who perform at social dancing events.

I chose this app as the chances are good that you, too, have some music lying around. If that does not describe you and you only use streaming services like Spotify, sorry!

The main job of the app is to scan your music folders and extract metadata from the tracks. You can then find music based on the metadata much faster, especially if your library is huge.

You‚Äôll find the repository [here](https://github.com/teekay/litedb-sqlite-handbook). I encourage you to follow along using your favorite code editor!

The main contract is the interface `IDBManager`. It is quite large, but we‚Äôll only worry about a few methods in the course of this chapter.

We will implement the interface using LiteDB. When we are done, we can compare both implementations by various metrics such as:

- API ease of use
- database size
- query performance

## Introducing the model classes

The music library deals with tracks and playlists.

We‚Äôll make our job easy and use a flat data structure without normalizing the data.

We could extract genres and artists and do some [normalization](https://en.wikipedia.org/wiki/Database_normalization), of course. However, this handbook isn‚Äôt about that. You may want to consider database normalization in your own projects, however.

The schemas are implemented as POCOs.

First, the track schema:

```csharp
internal class Track
{
    public int Id { get; set; }

    public string? Uri { get; set; }

    public string? Title { get; set; }

    public string? Artist { get; set; }

    public string? AlbumArtist { get; set; }

    public string? Conductor { get; set; }

    public string? Album { get; set; }

    public string? Genre { get; set; }

    public string? Grouping { get; set; }

    public string? Year { get; set; }

    public long Duration { get; set; }

    public string? Comment { get; set; }

    public double BPM { get; set; }

    public double ReplayGain { get; set; }

    public int Rating { get; set; }

    public long StartTime { get; set; }

    public long EndTime { get; set; }

    public byte[]? WaveformData { get; set; }

    public long LastScannedOn { get; set; }

    public bool ConfirmedReadable { get; set; }

    public string? SearchIndex { get; set; }
}
```

The playlist schema:

```csharp
internal class Playlist : IPersistedPlaylist
{
    private string _uri = string.Empty;
    private string _comment = string.Empty;

    public int Id { get; set; }

    public string Uri
    {
        get => _uri;
        set => _uri = value ?? string.Empty;
    }

    public string Comment
    {
        get => _comment;
        set => _comment = value ?? string.Empty;
    }

    public long LastScannedOn { get; set; }
}
```

Then there‚Äôs a collection that maps tracks to playlists. 

```csharp
internal class PlaylistTrack
{
    public int PlaylistId { get; set; }
    public int TrackId { get; set; }
    public int Position { get; set; }
    public long CreatedAt { get; set; }
}
```

This is a leftover from the SQLite implementation, which used a table to map tracks to playlists. We will refactor this later: in LiteDB, we can have embedded documents, and fields can reference documents in other collections, similar to how SQL databases support cross-table references.

With this model, we can support an app that scans folders for music files, extracts metadata from them, and stores them for analysis and queries.

## Creating test data

Let‚Äôs build our database first so that you can work with your own music. That way, you won‚Äôt have to deal with my odd musical taste (I am a tango nerd ü§ì).

Clone the [git repository](https://github.com/teekay/litedb-sqlite-handbook) or download the published binary.

The program does not need to be installed. Open Terminal and run:

```powershell
.\MusicLibrary.Cli.exe scan -d litedb -i path-to-your-music -o path-to-generated-database-file
```

The first argument `-d` determines the DB API to use (`sqlite` or `litedb`). The argument `-i` specifies the path to your music folder, e.g., `C:\Users\John\Music`. The last argument `-o` controls where you want the program to store the generated database. 

The program will run for a while, depending on your library's size. It will output the names of scanned folders and how far along it is in percent.

<aside>
üí° The program only reads the metadata in your music files. It does not change anything in them.

</aside>

## Creating the database schema

SQLite has tables, LiteDB has collections.

The two are not identical concepts, but we will treat them as such anyway.

You can create your database schema in SQLite upfront. That option does not exist in LiteDB. LiteDB creates a collection when you insert the first document into it or when you create one or more indices.

<aside>
<p>üí° When using SQLite-net, you don‚Äôt have to create the database schema first either; the library can do it for you when you call <code lang="csharp">Connection.EnsureTable&lt;CreateTable&gt;</code>.</p>

<p>Compare:</p>

<table>
    <tr>
        <th>SQLite-net</th>
        <th>LiteDB</th>
    </tr>
    <tr>
        <td>
            <code lang="csharp">Connection.CreateTable<Track>(); // collection is created now if it does not exist</code>
        </td>
        <td>
            <code lang="csharp">
var tracks = db.GetCollection<Track>("tracks");
tracks.EnsureIndex(t => t.Uri); // collection is created now if it does not exist
            </code>
        </td>
    </tr>
</table>
</aside>

Notice that we‚Äôre talking about a schema even though LiteDB does not force you to have one.

For anything bigger than a toy project or a one-off prototype, you will end up designing the schema with a similar level of precision that you would for a SQL database.

You will have objects that have properties, most often strongly-typed, and these objects either map to one or more tables or one or more documents.

### About indices

Having well-designed indexes will add a positive performance boost to your queries. We will test that later.

LiteDB implements [just one type of index](https://www.litedb.org/docs/indexes/) called ‚ÄúSkip lists‚Äù. It supports ‚Äúnormal‚Äù field indexes, indexes on array fields, and indexes with expressions.

SQLite has the upper hand here, supporting all kinds of indexes, including [indexes on expressions, unique indexes, partial indexes](https://www.litedb.org/docs/indexes/), etc.

Whether or not this makes any difference to your app performance is an open question. We‚Äôll try to answer it at least partially when comparing query performance between SQLite and LiteDB later in this document.

## Creating your model classes

How do you code your persistence layer using LiteDB? You have several options, and you can mix and match them to fit your needs.

### Working with documents

A LiteDB document - `BsonDocument` - is a collection of key-value pairs. You can work [directly with documents](https://github.com/mbdavid/LiteDB/wiki/BsonDocument) like this:

```csharp
var track = new BsonDocument();
track["Title"] = "Coraz√≥n, qu√© has hecho";
track["Artist"] = "Antonio Rodio / Alberto Serna";
track["Year"] = "1943";
// etc.
using(var db = new LiteDatabase("music.db"))
{
    var col = db.GetCollection("tracks");
    
    // Insert the document into the database. This will create the collection if it does not exist yet.
    col.Insert(track);
}
```

This is how you would later find your document:

```csharp
var track = col.FindOne("$.Title = 'Coraz√≥n, qu√© has hecho'");
```

This approach might be convenient when your document only has a few properties.

Like any dictionary with string keys, it leaves the job of creating and enforcing the schema to you. I would only recommend this approach for the initial prototyping or for small, specialized documents where there is no domain equivalent.

### Using data-transfer objects (DTOs)

You can use classes and LINQ to create and manipulate your data in a strongly typed fashion:

```csharp
public class Track
{
    public string Title { get; set; }
    public string Artist { get; set; }
    public string Year { get; set; }
  // etc.
}

using(var db = new LiteDatabase("music.db"))
{
    var col = db.GetCollection("tracks");
    
    // Insert the document into the database. This will create the collection if it does not exist yet.
    col.Insert(
        new Track 
        {
            Title = "Coraz√≥n, qu√© has hecho",
            Artist = "Antonio Rodio / Alberto Serna",
            Year = "1943"
       });
}
```

This is how you would later find your document:

```csharp
var track = col.FindOne(t => t.Title = "Coraz√≥n, qu√© has hecho");
```

Notice that thanks to strong types, you can now use LINQ to query your database. More on that later.

While I am not a big fan of DTOs, this approach has the easiest API. I would advise you to keep your DTOs private to your database layer and convert them to proper domain objects to use in your app.

### Using a custom mapper

You might be able to skip the DTOs entirely and use a custom mapper to convert your domain objects to documents that LiteDB can store.

Suppose you have a class `Song` that encapsulates track metadata and provides an audio stream for playback:

```csharp
public class Song
{
  public Song(string path, string title, string artist)
  {
    Path = path;
        Title = title;
        Artist = artist;
    Length = LengthFromMetadata(); // assume this reads the length of the decoded byte stream
  }

    public string Path { get; }

    public string Title { get; }

    public string Artist { get; }

    public long Length { get; }

    // other metadata

    public Stream Notes()
  {
        // read the audio file and return a PCM stream, for example
  }
}
```

You might not need to do anything special to serialize your class to a `BsonDocument`.

You can, however, customize the serialization. You can decide what the document ID should be, which fields to store, and how to name the fields in the document.

For simple classes, the built-in fluent mapper works great.

```csharp
var mapper = BsonMapper.Global;
mapper.Entity<Song>()
    .Id(x => $"{x.Title}|{x.Artist}") // set a custom ID
    .Ignore(x => x.Length) // do not store this property
    .Field(x => x.Title, "Name") // choose a different name for a property
    .Ctor(doc => new Song(doc["Path"], doc["Name"], doc["Artist"])); // tell LiteDB how to construct your domain object
```

If your class is more complex or you have special needs, you can define how the class instance should be (de)serialized.

For example, you could choose to store track duration in seconds instead of ticks. This is how you would do it:

```csharp
var mapper = new BsonMapper(); // or BsonMapper.Global
mapper.RegisterType<TimeSpan>(
    serialize: t => t.TotalSeconds,
    deserialize: bson => TimeSpan.FromSeconds(bson.AsDouble)
);
```

Or, you could empower your model class and create a serialization method as well as a constructor that accepts a `BsonDocument`, parses its fields, and populates its own properties:

```csharp
var mapper = new BsonMapper(); // or BsonMapper.Global
mapper.RegisterType<Track>(
    serialize: t => t.AsDocument(),
    deserialize: bson => new Track(bson.AsDocument)
);
```

I found out during my tests that using this approach yielded an approx. 20% performance gain compared to letting LiteDB do the conversion between the `BsonDocument` and the model class on its own. This is probably because this way, you don‚Äôt pay the reflection tax.

<aside>
üí° You can inspect the source code of `Track.cs` to examine the details of both the serialization method `ToDocument()` as well as the constructor that converts the `BsonDocument` instance to class.

</aside>

### Using a specialized constructor

Alternatively, you can annotate a constructor with the attribute `[BsonCtor]` and tell LiteDB how to convert a `BsonDocument` to your class instance.

Defying reasonable expectations, the constructor can‚Äôt have a single argument of type `BsonDocument` but rather a list of attributes to be assigned to the class properties (see [this Github issue](https://github.com/mbdavid/LiteDB/issues/1699)).

The constructor arguments should have the same name as the properties, although the case does not matter. This is how you would do it:

```csharp
public class Song
{
    public Song()
    {
        Length = ReadLength();
    }

    [BsonCtor] //  <- here
    public Song(string path, string tItLe, string Artist) : base()
    {
        this.Title = tItLe;
        this.Path = path;
        this.Artist = Artist;
    }

    private long ReadLength()
    {
        // e.g. read the stream length from metadata
    }

    public string Title { get; }

    public string Path { get; }

    public string Artist { get; }

    public long Length { get; }
}
```

I would advise against using this approach.

It‚Äôs useless for DTOs (use public getters and setters instead), and it would marry your domain classes to the persistence layer if you used it there.

If you don‚Äôt want to use DTOs and would rather map directly between your domain objects and documents, use the fluent API and/or custom entity serialization. This gives you the most flexibility and lets you keep your concerns separate.

## Making queries

How do you get data out of LiteDB? You have several options.

### Using SQL

Let‚Äôs say we want to retrieve a list of all musical genres from tracks in our library.

This is an analytical operation, and the result is a list of string values.

You could use LINQ both with SQLite-net and LiteDB to get this information. However, I think using SQL is more elegant.

This is what the SQLite-net implementation looks like:

```csharp
public IEnumerable<string> Genres()
{
    return Connection.QueryScalars<string>(
            "select distinct genre from tracks where genre is not null order by genre");
}
```

Compare with LiteDB:

```csharp
public IEnumerable<string> Genres()
{
    return db.Execute(@"select distinct(*.Genre) as genres from tracks where $.Genre != null order by $.Genre")
        .Current["genres"]
        .AsArray
        .Select(x => x.AsString);
}
```

There‚Äôs just a little bit more work involved here to grab the results array and map each `BsonValue` instance to a string.

### Using LINQ

A very common use case is to fetch tracks by a certain artist or of a certain genre.

In this case, you want to receive all the information. You‚Äôll convert the result set to your domain objects and work with them in your app.

Both SQLite-net and LiteDB have a LINQ API. The implementation differs by the extent to which they implement the LINQ API.

SQLite-net:

```csharp
public IEnumerable<ITrack> ByGenreWithLinq(string genreName)
{
    return (string.IsNullOrWhiteSpace(genreName) || string.IsNullOrEmpty(genreName)
            ? Connection.Table<Track>().Where(t => t.Genre == null || t.Genre == @"" || t.Genre == @" ")
            : Connection.Table<Track>().Where(t => t.Genre == genreName))
            .OrderBy(t => t.Artist)
            .ThenBy(t => t.Title)
            .Select(ModelMappedToITrack);
}
```

LiteDB:

```csharp
public IEnumerable<ITrack> ByGenre(string genreName)
{
    var col = db.GetCollection<Track>("tracks");

    return (string.IsNullOrWhiteSpace(genreName)
        ? col.Query()
            .Where(t => t.Genre == null || t.Genre == string.Empty || t.Genre == " ")
        : col.Query()
            .Where(t => t.Genre == genreName))
        .ToList()
        .OrderBy(t => t.Artist)
        .ThenBy(t => t.Title)
        .Select(ModelMappedToITrack);
}
```

LiteDB does not support ordering the results by more than one column, hence we‚Äôre ordering the returned data set with LINQ after we‚Äôve received the data from LiteDB.

<aside>
üí° The `ITrack` interface is a contract for the domain object. The last method call (`ModelMappedToITrack`) does the conversion from the DTO to the domain object. We don't have to worry about the domain objects here; those exist to support the playback of the actual audio files and populate the GUI of the Bewitched app.

</aside>

## Adding, updating, and deleting documents

TODO: this section does not have SQLite-net code samples

### Using collection methods

We‚Äôve seen that adding a new document to LiteDB is trivial.

You ask the database to give you a reference to a particular collection:

```csharp
var col = db.GetCollection<Track>("tracks");
```

Then, after instantiating your model and filling it with values, you ask the collection to insert the document:

```csharp
var track = new Track();
// populate the properties
col.Insert(track);
```

LiteDB also gives you a way to do a bulk insert of several models in one go:

```csharp
var tracks = new List<Track>()
{
    new Track() { Uri = @"C:\Users\John\Music\song1.mp3" },
    new Track() { ... },
    // etc.
}
col.InsertBulk(tracks);
```

For updating, the API is similarly straightforward:

```csharp
var track = col.FindOne(t => t.Uri == somePath);
// do your updating
col.Update(track);
```

When the time comes to delete a particular record, you have a few options:

- Delete a record by its ID: `col.Delete(track.Id)`
- Bulk delete using an expression: `col.DeleteMany($"$.PlaylistId = {[playlist.Id](http://playlist.id/)}")` (here, the collection contains IDs of tracks used in a particular playlist, and we are removing all that are associated with a particular playlist)

### Using SQL

You can accomplish the same results using the LiteDB SQL API.

We‚Äôve seen the Read example above when discussing how to fetch a list of genres from our music library.

Using the SQL API for update operations can be useful when running bulk operations on multiple documents, e.g., when you change your schema and need to update existing documents.

Suppose you want to add a convenience field `DisplayTitle` that combines the track artist and title (you would normally do this in your domain object, of course):

```csharp
db.Execute("update songs set DisplayTitle = join([$.Artist, ': ', $.Title])");
```

Likewise, say you deleted all songs by a given band because you grew tired of them, this is how you would delete them from the database with the SQL API:

```csharp
db.Execute("delete songs where Artist = 'Boomers'");
```

<aside>
üí° Notice the syntax is `delete <collectionName` not `delete FROM <collectionName>`

</aside>

Cool, isn‚Äôt it?

What‚Äôs also very cool is the built-in support for populating your database from a JSON file.

You can export JSON from your source (be it an API or another database - both SQLite and Postgres, among others, can do this for you) and import it into LiteDB like this:

```sql
insert into collectionname:int from $file('/path/to/file')
```

<aside>
üí° The type information after the colon (`collectionname:int`) specifies what kind of primary key you want - it can be an ObjectId (default), int, long, or GUID.

</aside>

We will look into this in the migration chapter.

## Embedded documents and collection references

SQL databases encourage you to normalize your schema to eliminate redundancy and ensure the integrity of your data.

Document databases have no such ambition. By design, they have far fewer constraints that you could use to map relationships between documents.

The way you enforce these in SQL databases is by using foreign keys. Here, SQLite is intentionally less strict and even has [foreign key constraints](https://sqlite.org/foreignkeys.html) disabled by default. This can be convenient when you are working with ‚Äúdirty‚Äù data.

LiteDB has no foreign keys.

It has two features that let you map relationships between entities:

- embedded documents
- collection references

### Embedded documents

Suppose we refactored our model class like this:

```csharp
public class Track
{
    public int Id { get; set; }
    public string Uri { get; set; }
  public Metadata Meta { get; set; }
}

public class Metadata
{
  public string? Title { get; set; }

  public string? Artist { get; set; }

  public string? AlbumArtist { get; set; }

  public string? Conductor { get; set; }

  // etc.
}
```

The metadata for each track would now be an embedded document. Since the metadata is unique to each track, that might be the right design choice.

You can still make easy queries to look up tracks with specified metadata. There‚Äôs really nothing special about this; document databases give you this feature ‚Äúfor free.‚Äù

### Collection references

Now consider again the collection that maps how tracks are being used in playlists:

```csharp
internal class PlaylistTrack
{
    public int PlaylistId { get; set; }
    public int TrackId { get; set; }
    public int Position { get; set; }
    public long CreatedAt { get; set; }
}
```

This would be the correct design for a relational database: each property would map to a table column, and you would have foreign key relationships for `TrackId` and `PlaylistId`. In SQL, this is how you would fetch all tracks from a given playlist:

```csharp
var tracks = Connection.Query<Track>($"select t.* from Track t join PlaylistTracks pt on (t.Id=pt.TrackId)
where pt.PlaylistId=? order by pt.Position", playlistId);
```

You can still use this pattern with LiteDB, albeit enforcing your relationship constraints in code instead. When looking up tracks from a particular playlist, you would make two queries:

1. Fetch records from the `playlist_tracks` collection for a given `PlaylistId`: 

```csharp
 var tracksIds = db.GetCollection<PlaylistTrack>("playlist_tracks")
  .Query()
  .Where(pt => pt.PlaylistId == playlistId)
  .OrderBy(pt => pt.Position)
  .ToList()
  .Select(pt => pt.TrackId);
```

1. Fetch all tracks matching the returned IDs:

```csharp
 db.GetCollection<Track>("tracks")
  .Query()
  .Where($"$._id in ([{string.Join(",", trackIds)}])");
```

You can accomplish the same thing in one query using collection references.

First, we refactor the `PlaylistTrack` model:

```csharp
internal class PlaylistTrack
{
    public int PlaylistId { get; set; }
    public Track Track { get; set; }
    public int Position { get; set; }
    public long CreatedAt { get; set; }
}
```

Then we tell LiteDB to store `Track` as a reference to the `tracks` collection:

```csharp
BsonMapper.Global.Entity<PlaylistTrack>()
                .DbRef(pt => pt.Track, "tracks");
```

Alternatively, you could annotate the `Track` property using `BsonRef` to achieve the same result:

```csharp
internal class PlaylistTrack
{
    public int PlaylistId { get; set; }

        [BsonRef("tracks")] // <- here
    public Track Track { get; set; }

    public int Position { get; set; }
    public long CreatedAt { get; set; }
}
```

Choose whichever approach works better in your scenario.

The query looks like this:

```csharp
var tracks = db.GetCollection<PlaylistTrack>("playlist_tracks")
               .Query()
                             .Include(pt => pt.Track) // <- here
               .Where(pt => pt.PlaylistId == playlistId)
               .OrderBy(pt => pt.Position)
               .ToList()
               .Select(pt => MappedToDomain(pt.Track))
```

Notice that all you have to do is to ask LiteDB to fetch the related document using the `Include` method call. Neat, isn‚Äôt it?

Or, you can utilize the SQL API:

```csharp
db.Execute($"SELECT $.Track FROM playlist_tracks INCLUDE $.Track WHERE $.PlaylistId={playlist.Id} ORDER BY $.Position")
                .ToEnumerable()
                .Select(doc => MappedToDomain(new Track(doc["Track"].AsDocument)));
```

In my tests, the LINQ API performed a little better. Fetching took 54 ms. using LINQ and 66 ms. using SQL.

## Concurrency considerations

While you can have multiple readers attached to the same database, you will quickly run into problems if you were to have several threads attempting to execute database writes at the same time.

Neither SQLite nor LiteDB is a client/server database, and neither supports parallel write operations.

If your app is single-threaded (e.g., a simple console tool), you might get away with ignoring this limitation. In most real-world use cases, you‚Äôll want to ensure that all database transactions are committed sequentially and that you have exactly one active database connection for writes.

This isn‚Äôt terribly difficult to enforce, especially if you are using dependency injection. You will open the database connection at your application‚Äôs startup and dispose of it when the app shuts down.

In multi-threading scenarios, you‚Äôll also want to enforce the sequential nature of all commits.

In the music library project that we‚Äôre working on, we are using a class `SequentialDbWriter` that internally uses an instance of `[BlockingCollection<T>](https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent.blockingcollection-1?view=net-6.0)` where `T` is an `Action`.

It exposes a method that the `LiteDbMusicLibrary` instance calls to perform an INSERT, UPDATE, or DELETE operation:

```csharp
public void Commit(Action commitAction)
{
  if (_commitQueue.IsAddingCompleted) return;
  _commitQueue.Add(commitAction); // this is the BlockingCollection<T> instance
}
```

It runs a loop on another thread, and whenever an item is added to the `_commitQueue`, it invokes the passed `commitAction`.

This way performs well even in demanding scenarios, e.g., when you scan your entire music library for the first time.

## Performance shoot-out

Time to test for performance.

A note about my testing methodology: it is not scientific. ü§£

We are not comparing the performance using tools that could be considered ‚Äúnative‚Äù or ‚Äúofficial,‚Äù such as the [SQLite client](https://sqlite.org/cli.html) or the [LiteDB Studio](https://github.com/mbdavid/LiteDB.Studio). We are interested in the real-world performance using the databases in a .NET application.

The tests used the command-line tool I have included in the collateral to this handbook, built with the Release configuration.

Given a contract specified in the interface `IDBManager`, I will make an implementation using SQLite-net and LiteDB. For each method, I will try to use a similar approach in both implementations.

So, for instance, if a given method can accomplish its task with SQL, I used the SQL API for both databases.

Of course, even as they might look similar on the surface, each uses a different code ‚Äúunder the hood.‚Äù

### **Test setup**

The test machine had the following specs:

- AMD Ryzen 3950X (16 cores, 32 threads)
- 64 GB RAM
- Samsung 970 EVO 1 TB M2 SSD
- Seagate BarraCuda 4 TB SATA HDD

As LiteDB uses write-ahead logging (WAL) to ensure transaction integrity, I enabled WAL for SQLite, too (SQLite has [a few other options](https://sqlite.org/pragma.html#pragma_journal_mode), and WAL is only available from version 3.7).

Since the application runs on a single thread, all write methods commit directly (see Concurrency considerations above).

All tests run with the program compiled in the Release configuration. 

### **The initial scanning**

My music library had 8328 at the time of writing.

The program iterates all folders, reads metadata from the music files, and syncs them with the database.

Results when reading from the SSD:

| SQLite-net | LiteDB |
| --- | --- |
| 1 minute 23 seconds | 1 minute 27 seconds |

The results varied by a few seconds when repeated. Result: a draw.

As one would expect, the operation takes longer when the data is on an HDD.

| SQLite-net | LiteDB |
| --- | --- |
| 3 minutes 25 sec | 3 minutes 18 seconds |

Since I/O is the limiting factor here, there was no clear winner here either.

The size of the database file after the scanning finished was:

| SQLite | LiteDB |
| --- | --- |
| 6.8 MB | 13 MB |

I would attribute the difference to the fact that LiteDB is schemaless, and so each document must store all of its metadata.

### Query performance

Let‚Äôs compare the speed of a few typical queries.

Some of these queries represent use cases that the application implements. I have added others, e.g., a few bulk operations, to gather additional data points.

Get a list of all genres (67 in my collection):

```csharp
// SQLite-net:

public IEnumerable<string> Genres()
{
    return Connection.QueryScalars<string>(
        "SELECT DISTINCT Genre FROM Track WHERE Genre IS NOT NULL ORDER BY Genre");
}

// LiteDB:
public IEnumerable<string> Genres()
{
    return db.Execute(
        @"select distinct(*.Genre) as genres from tracks where $.Genre != null order by $.Genre")
    .Current["genres"]
    .AsArray
    .Select(x => x.AsString);
}
```

| SQLite | LiteDB |
| --- | --- |
| 2 ms. | 42 ms. |

Get a list of tracks by genre - given 5185 Tango tracks in my collection:

```csharp
// SQLite-net:
public IEnumerable<ITrack> ByGenre(string genreName)
        {
            return (string.IsNullOrWhiteSpace(genreName) || string.IsNullOrEmpty(genreName)
                    ? Connection.Table<Track>().Where(t => t.Genre == null || t.Genre == @"" || t.Genre == @" ")
                    : Connection.Table<Track>().Where(t => t.Genre == genreName))
                    .OrderBy(t => t.Artist).ThenBy(t => t.Title)
                    .Select(ModelMappedToITrack);
        }

// LiteDB:
public IEnumerable<ITrack> ByGenre(string genreName)
{
    return (string.IsNullOrWhiteSpace(genreName)
        ? _tracks.Query()
        .Where(t => t.Genre == null || t.Genre == string.Empty || t.Genre == " ")
        : _tracks.Query()
        .Where(t => t.Genre == genreName))
        .ToList()
        .OrderBy(t => t.Artist)
        .ThenBy(t => t.Title)
        .Select(MappedToDomain);
}
```

| SQLite | LiteDB |
| --- | --- |
| 88 ms. | 92 ms. |

The same query implemented using SQL:

```csharp
// SQLite-net:
public IEnumerable<ITrack> ByGenre(string genreName)
{
    return (string.IsNullOrWhiteSpace(genreName) || string.IsNullOrEmpty(genreName)
        ? Connection.Query<Track>("SELECT * FROM Track WHERE Genre IS NULL OR Genre=? OR Genre=? ORDER BY Artist, Title‚Äù, string.Empty, @" ")
        : Connection.Query<Track>("SELECT * FROM Track WHERE Genre=? ORDER BY Artist, Title‚Äù, genreName))
        .Select(ModelMappedToITrack);
}

// LiteDB:
public IEnumerable<ITrack> ByGenre(string genreName)
{
    var condition = string.IsNullOrWhiteSpace(genreName) ? " is null or $.Genre = \"\" or $.Genre = \" \"" : $" = \"{genreName}\"";
    var sql = $"select $ from tracks where $.Genre {condition}";
    return db.Execute(sql)
        .ToEnumerable()
        .Select(doc => new Track(doc.AsDocument))
        .ToList()
        .OrderBy(t => t.Artist)
        .ThenBy(t => t.Title)
        .Select(MappedToDomain);
}
```

| SQLite | LiteDB |
| --- | --- |
| 77 ms. | 98 ms. |

Insert a batch of 1000 tracks one by one:

```csharp
// SQLite-net:
public void Save(ITrack source)
{
    var model = _servesTracks.MappedToModel(source);
    _dbWriter.Commit(model.Id == 0
      ? (Action)(() => Connection.Insert(model))
      : () => Connection.Update(model));
}

// LiteDB:
public void Save(ITrack track)
{
    var model = MappedToModel(track);
    _dbWriter.Commit(model.Id == 0
      ? (Action)(() => _tracks.Insert(model))
      : () => _tracks.Update(model));
}
```

| SQLite | LiteDB |
| --- | --- |
| 170 ms. | 160 ms. |

Delete a batch of 1000 tracks one by one and also remove them from playlists:

```csharp
// SQLite-net:
public void Forget(string path)
{
     _servesTracks.InDirectory(path).ToList()
    .ForEach(found =>
    {
        _dbWriter.Commit(() => {
          Connection.Execute(@"delete from PlaylistTracks where TrackId=?", found.Id);
          Connection.Execute(@"delete from Track where Id=?", found.Id);
        });
    });
}

// LiteDB:
private void Forget(string path)
{
    var pathCi = path.ToLowerInvariant();
    var findSql = $"select $._id from tracks where $.Uri = \"{EscapePath(pathCi)}\"";
    var trackIds = db.Execute(findSql)
    .ToEnumerable()
    .Select(doc => doc["_id"].AsInt32)
    .ToList();
    if (!trackIds.Any())
    {
        return;
    }
    trackIds.ForEach(trackId =>
        _dbWriter.Commit(() =>
        {
            var deleteFromPlaylistsSql = $"delete playlist_tracks where $.TrackId = {trackId}";
            db.Execute(deleteFromPlaylistsSql);
            var deleteFromTracksSql = $"delete tracks where $._id = {trackId}";
            db.Execute(deleteFromTracksSql);
        })
    );
}
```

| SQLite | LiteDB |
| --- | --- |
| 2 - 3s. | 30 s. üò± |

Wow! This implementation clearly goes against LiteDB strengths, so let‚Äôs try another:

```csharp
// SQLite-net:
internal void ForgetUsingTableMethods(string path)
{
    _servesTracks.InDirectory(path).ToList()
    .ForEach(found =>
    {
        _dbWriter.Commit(() => {
          var trackInPlaylists = Connection.Table<PlaylistTrack>().Where(pt => pt.TrackId == found.Id).ToList();
        trackInPlaylists.ForEach(pt => Connection.Delete<PlaylistTrack>(pt.Id));
        Connection.Delete<Track>(found.Id);
      });
    });
}

// LiteDB:
public void Forget(string path)
{
    var tracks = _tracks.Query().Where(t => t.Uri == path).ToList();
    tracks.ForEach(track =>
    _dbWriter.Commit(() =>
        {
          _playlistTracks.DeleteMany($"$.TrackId = {track.Id}");
          _tracks.DeleteMany($"$._id = {track.Id}");
        })
    );
}
```

| SQLite | LiteDB |
| --- | --- |
| 1.5 s. | 30 s. üò± |

Nope, that wasn‚Äôt it. Contrary to my expectation, the alternative SQLite-net implementation performed better than the previous one using SQL, while LiteDB took 30 seconds again to complete the task.

OK, so when removing a large batch of records, it might be better to utilize the ‚Äúbulk operations‚Äù methods, right? Let‚Äôs see.

Delete 1000 tracks in batches of 50 (also removing them from playlists):

```csharp
// SQLite-net:
public void Forget(IEnumerable<ITrack> tracks)
{
    var paths = tracks.Select(t => t.Uri).ToList();
    _dbWriter.Commit(() =>
    {
        Connection.BeginTransaction();
        foreach (var chunk in paths.Chunk(50))
        {
            var @params = chunk.ToArray();
            var trackIds = Connection.QueryScalars<int>($"select Id from Track where Filepath in ({string.Join(", ", chunk.Select(p => @"?"))})", @params).Select(id => (object)id).ToArray();
            var deleteFromPlaylistSql = $"delete from PlaylistTracks where TrackId in ({string.Join(", ", trackIds.Select(p => @"?"))})";
            Connection.Execute(deleteFromPlaylistSql, trackIds);
            Connection.Execute($"delete from Track where Id in ({string.Join(", ", trackIds.Select(p => @"?"))})", trackIds);
        }
        Connection.Commit();
    });
}

// LiteDB:
public void Forget(IEnumerable<ITrack> tracks)
{
    var paths = tracks.Select(t => t.Uri).ToList();
    _dbWriter.Commit(() =>
    {
        foreach (var chunk in paths.Chunk(50))
        {
            var findSql = $"select $._id from tracks where $.Uri in ([{string.Join(", ", chunk.Select(p => $"\"{EscapePath(p)}\""))}])";
            var trackIds = db.Execute(findSql)
                .ToEnumerable()
                .Select(doc => doc["_id"].AsInt32)
                .ToList();
            var deleteFromPlaylistsSql = $"delete playlist_tracks where TrackId in ([{string.Join(", ", trackIds)}])";
            db.Execute(deleteFromPlaylistsSql);
            var deleteFromTracksSql = $"delete tracks where _id in ([{string.Join(", ", trackIds)}])";
            db.Execute(deleteFromTracksSql);
        }
    });
}
```

| SQLite | LiteDB |
| --- | --- |
| 70 - 140 ms. | 2.5 s. |

LiteDB performs way better here, although SQLite still has the upper hand.

Lastly, let‚Äôs fetch all tracks from a given playlist:

```csharp
// SQLite-net:
public IEnumerable<ITrack> Contents(IPersistedPlaylist playlist)
{
    const string sql = @"SELECT a.* FROM Track a JOIN PlaylistTracks b WHERE b.PlaylistId=? AND a.Id=b.TrackId ORDER BY b.Position";
    return Connection.Query<Track>(sql, playlist.Id).Select(ModelMappedToITrack);
}

// LiteDB:
public IEnumerable<ITrack> Contents(IPersistedPlaylist playlist)
{
    return _playlistTracks.Query()
        .Include(pt => pt.Track)
        .Where(pt => pt.PlaylistId == playlist.Id)
        .OrderBy(pt => pt.Position)
        .ToList()
        .Select(pt => MappedToDomain(pt.Track));
}
```

| SQLite | LiteDB |
| --- | --- |
| 5 ms. | 52 s. |

### Summary and conclusions

In all but one test, the SQLite-net implementation fared better. Sometimes, way better.

The worst performer was the test of deleting a thousand records one by one. By all indications, it‚Äôs way better to do this in batches.

Despite the results, you may very well not feel the difference in real life. Whether a read query takes 5 or 50 milliseconds to complete may not be the limiting factor. If the other parts of your application are well designed, the user may be unable to tell the difference.

\newpage
